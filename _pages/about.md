---
layout: about
title: About
permalink: /
subtitle: he-ming.xia AT connect.polyu.hk

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular

selected_papers: true # includes a list of papers marked as "selected={true}"

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder
---

I am Heming Xia (Â§èÈπ§Êòé), a Ph.D. student in the [NLP Group](https://polyunlp.github.io/) at The Hong Kong Polytechnic University, supervised by Prof. [Wenjie Li](https://www4.comp.polyu.edu.hk/~cswjli/). I earned my master's degree from the [MOE Key Lab of Computational Linguistics](https://icl.pku.edu.cn/) at Peking University, where I was advised by Prof. [Zhifang Sui](https://cs.pku.edu.cn/info/1226/2014.htm). Prior to that, I completed my bachelor's degree in physics at the [School of Physics](http://english.phy.pku.edu.cn/info/1017/5151.htm), Peking University in 2020. I have previously worked as a research intern at the [NLC Group, Microsoft Research Asia](https://www.microsoft.com/en-us/research/group/natural-language-computing/) and [SEA AI Lab](https://sail.sea.com/), where I had the privilege of collaborating with Dr. [Tao Ge](https://scholar.google.com/citations?user=LYbs7Q8AAAAJ&hl=en) and Dr. [Cunxiao Du](https://nonvolatilememory.github.io/). For more details, please see my [CV](https://hemingkx.github.io/assets/pdf/CV.pdf).

üì¨ *I am open to collaborating with highly motivated students on research related to (but not limited to) the topics below. If interested, please feel free to reach out via email.*

# Research

My research focuses on efficient and effective NLP, with the goal of making LLMs faster, more scalable, and broadly applicable. Specifically, my work centers on the following directions:

- **Speculative Decoding:** Exploring inference acceleration techniques that maintain output fidelity. This includes our pioneering work on Speculative Decoding [[EMNLP'23-findings](https://aclanthology.org/2023.findings-emnlp.257/), [ICLR'25](https://openreview.net/forum?id=EKJhH5D5wA)], the widely used benchmark [Spec-Bench](https://sites.google.com/view/spec-bench) and the first comprehensive survey [[ACL'24-findings](https://aclanthology.org/2024.findings-acl.456/)] in this paradigm.
- **Efficient Reasoning:** Developing advanced algorithms to enhance the efficiency of reasoning models, spanning efficient training strategies, inference acceleration [[EMNLP'25](https://aclanthology.org/2025.emnlp-main.165/), [arXiv'25](https://arxiv.org/abs/2510.10528)], and dense representations such as latent CoT [[arXiv'25](https://arxiv.org/abs/2505.16782)].
- **Applications (Efficiency + X):** I am interested in how efficiency-oriented techniques can benefit broader applications, with recent focus on tool-augmented agents and multimodal models [[EMNLP'25](https://aclanthology.org/2025.emnlp-main.366/)].

In addition, I am actively working on tool learning [e.g., [EMNLP'24](https://aclanthology.org/2024.emnlp-main.856/), [ACL'25-findings](https://aclanthology.org/2025.findings-acl.1107/)] and vision-language understanding [e.g., [ACL'22](https://aclanthology.org/2022.acl-long.66/), [EMNLP'23-findings](https://aclanthology.org/2023.findings-emnlp.133/), [EMNLP'25-findings](https://aclanthology.org/2025.findings-emnlp.342/)].
